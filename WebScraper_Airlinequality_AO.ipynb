{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPER AO - AIRLINEQUALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Air Inequality\n",
    "https://www.airlinequality.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL \n",
    "ae_url = 'https://www.airlinequality.com/'\n",
    "ae_url_airfrance = 'https://www.airlinequality.com/airline-reviews/air-france/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Get Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "req = Request(ae_url_airfrance,headers=hdr)\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page)\n",
    "\n",
    "\n",
    "l_titles = []\n",
    "\n",
    "bodies = soup.body\n",
    "\n",
    "bodies = soup.find_all(\"div\", {\"class\":\"body\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get general value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = soup.find('div', {'class':'info'})\n",
    "company_name = company.h1.text.strip()\n",
    "\n",
    "l_global_value_header = []\n",
    "l_global_value_stars = []\n",
    "\n",
    "stats = soup.table\n",
    "tdTags = stats.find_all(\"td\")\n",
    "for tag in tdTags:\n",
    "    if 'header' in tag['class'][0]:\n",
    "        l_global_value_header.append(tag.text)\n",
    "    if 'stars' in tag['class'][0]:\n",
    "        tag_values = tag.find_all('span', {'class':'star fill'})\n",
    "        l_global_value_stars.append(int(tag_values[-1].text))\n",
    "\n",
    "l_global = [('company_name', company_name)] + list(zip(l_global_value_header, l_global_value_stars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = soup.find('article', {'class':'comp comp_reviews-pagination querylist-pagination position-'})\n",
    "l_pages = pages.find_all('li')\n",
    "max_page = int(l_pages[-2].text.strip())\n",
    "max_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Reviews values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "l_titles = []\n",
    "l_reviewer_data = []\n",
    "l_verifications = []\n",
    "l_reviews = []\n",
    "l_stats = []\n",
    "for i in range(len(bodies)):\n",
    "    title = bodies[i].h2.text\n",
    "    l_titles.append(title)\n",
    "\n",
    "    reviewer_data = bodies[i].h3.text #to be proccessed\n",
    "    l_reviewer_data.append(reviewer_data)\n",
    "\n",
    "    review = bodies[i].find(\"div\", {'class':'text_content'})\n",
    "    verification = review.a.text\n",
    "    l_verifications.append(verification)\n",
    "    review = review.text #to be proccessed \n",
    "    l_reviews.append(review)\n",
    "\n",
    "    l_review_value = []\n",
    "    l_review_value_header = []\n",
    "    l_review_value_stars = []\n",
    "\n",
    "    stats = bodies[i].table\n",
    "    tdTags = stats.find_all(\"td\")\n",
    "    #print(tdTags)\n",
    "    for tag in tdTags:\n",
    "        #print(tag['class'][0], tag)\n",
    "        if 'header' in tag['class'][0]:\n",
    "            l_review_value_header.append(tag.text)\n",
    "        if tag['class'][0] == 'review-value':\n",
    "            l_review_value.append(tag.text)\n",
    "        if 'stars' in tag['class'][0]:\n",
    "            tag_values = tag.find_all('span', {'class':'star fill'})\n",
    "            l_review_value_stars.append(int(tag_values[-1].text))\n",
    "    l_review_value[-1:-1] = l_review_value_stars\n",
    "    \n",
    "    l_stats.append(list(zip(l_review_value_header, l_review_value)))\n",
    "\n",
    "print(len(l_titles) == len(bodies))\n",
    "print(len(l_reviewer_data) == len(bodies))\n",
    "print(len(l_verifications) == len(bodies))\n",
    "print(len(l_reviews)== len(bodies))\n",
    "print(len(l_stats) == len(bodies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform our data to dataframes\n",
    "dfs = [pd.DataFrame(l) for l in l_stats]\n",
    "\n",
    "#Merge accoring to column 0\n",
    "df = reduce(lambda left,right: pd.merge(left,right,on=0, how='outer'), dfs)\n",
    "\n",
    "#Get the right format of dataframe\n",
    "df_reviews = df.T.copy()\n",
    "df_reviews.columns = df_reviews.iloc[0]\n",
    "df_reviews.drop(df_reviews.index[0], inplace=True)\n",
    "df_reviews.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type Of Traveller</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Route</th>\n",
       "      <th>Date Flown</th>\n",
       "      <th>Seat Comfort</th>\n",
       "      <th>Cabin Staff Service</th>\n",
       "      <th>Food &amp; Beverages</th>\n",
       "      <th>Ground Service</th>\n",
       "      <th>Value For Money</th>\n",
       "      <th>Recommended</th>\n",
       "      <th>Inflight Entertainment</th>\n",
       "      <th>Aircraft</th>\n",
       "      <th>Wifi &amp; Connectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Prague to Cape Town via Paris</td>\n",
       "      <td>January 2020</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Toronto to Paris</td>\n",
       "      <td>December 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>Paris to Chicago</td>\n",
       "      <td>January 2020</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "      <td>A330-300</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>Paris to Madrid</td>\n",
       "      <td>January 2020</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>A320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Paris to Prague</td>\n",
       "      <td>December 2019</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A321</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 Type Of Traveller       Seat Type                          Route  \\\n",
       "0      Solo Leisure   Economy Class  Prague to Cape Town via Paris   \n",
       "1      Solo Leisure   Economy Class               Toronto to Paris   \n",
       "2          Business  Business Class               Paris to Chicago   \n",
       "3      Solo Leisure  Business Class                Paris to Madrid   \n",
       "4      Solo Leisure   Economy Class                Paris to Prague   \n",
       "\n",
       "0     Date Flown Seat Comfort Cabin Staff Service Food & Beverages  \\\n",
       "0   January 2020            1                   5                1   \n",
       "1  December 2019            5                   1                1   \n",
       "2   January 2020            4                   4                4   \n",
       "3   January 2020            1                   2                1   \n",
       "4  December 2019            3                   4                4   \n",
       "\n",
       "0 Ground Service Value For Money Recommended Inflight Entertainment  Aircraft  \\\n",
       "0              1               1          no                    NaN       NaN   \n",
       "1              5               1          no                      2       NaN   \n",
       "2              2               4         yes                      4  A330-300   \n",
       "3              3               1          no                      1      A320   \n",
       "4              1               3         yes                    NaN      A321   \n",
       "\n",
       "0 Wifi & Connectivity  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                   3  \n",
       "3                   1  \n",
       "4                   5  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_airlinequality(url):\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    req = Request(url,headers=hdr)\n",
    "    page = urlopen(req)\n",
    "    soup = BeautifulSoup(page)\n",
    "\n",
    "    page_soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "    company = soup.find('div', {'class':'info'})\n",
    "    company_name = company.h1.text.strip()\n",
    "\n",
    "    l_global_value_header = []\n",
    "    l_global_value_stars = []\n",
    "\n",
    "    stats = soup.table\n",
    "    tdTags = stats.find_all(\"td\")\n",
    "    for tag in tdTags:\n",
    "        if 'header' in tag['class'][0]:\n",
    "            l_global_value_header.append('global ' + tag.text)\n",
    "        if 'stars' in tag['class'][0]:\n",
    "            tag_values = tag.find_all('span', {'class':'star fill'})\n",
    "            l_global_value_stars.append(int(tag_values[-1].text))\n",
    "\n",
    "    l_global = [('company_name', company_name)] + list(zip(l_global_value_header, l_global_value_stars))\n",
    "    \n",
    "    bodies = soup.body\n",
    "\n",
    "    bodies = soup.find_all(\"div\", {\"class\":\"body\"})\n",
    "    \n",
    "    l_df = [] #a list that stores data of the url\n",
    "    \n",
    "    for i in range(len(bodies)):\n",
    "        \n",
    "        l_data_url = [] #a list that stores data of the review of the url (zip format)\n",
    "        l_data_url += l_global #we add global values for each reviews\n",
    "        \n",
    "        title = bodies[i].h2.text\n",
    "        title = title.strip('\"')\n",
    "        l_data_url.append(('title', title))\n",
    "        \n",
    "        reviewer_data = bodies[i].h3.text.strip() \n",
    "        reviewer_data = reviewer_data.split('\\n')[-1]\n",
    "        \n",
    "        date = ' '.join(reviewer_data.split()[-3:]) #the date is the last words of reviewer data\n",
    "        country = reviewer_data.split('(')[-1].split(')')[0] #we split according to '(' and ')'\n",
    "        \n",
    "        l_data_url.append(('date', date))\n",
    "        l_data_url.append(('country', country))\n",
    "        \n",
    "        review = bodies[i].find(\"div\", {'class':'text_content'})\n",
    "        verification = review.a\n",
    "        if verification is None:\n",
    "            l_data_url.append(('verification', np.nan))\n",
    "        else:\n",
    "            l_data_url.append(('verification', verification.text))\n",
    "        \n",
    "        review_content = review.text\n",
    "        review_content = review_content.split('| ')[-1]\n",
    "        l_data_url.append(('review', review_content))\n",
    "        \n",
    "        l_review_value = []\n",
    "        l_review_value_header = []\n",
    "        l_review_value_stars = []\n",
    "\n",
    "        stats = bodies[i].table\n",
    "        tdTags = stats.find_all(\"td\")\n",
    "        for tag in tdTags:\n",
    "            if 'header' in tag['class'][0]:\n",
    "                l_review_value_header.append(tag.text)\n",
    "            if tag['class'][0] == 'review-value':\n",
    "                l_review_value.append(tag.text)\n",
    "            if 'stars' in tag['class'][0]:\n",
    "                tag_values = tag.find_all('span', {'class':'star fill'})\n",
    "                if len(tag_values) != 0:\n",
    "                    l_review_value_stars.append(int(tag_values[-1].text))\n",
    "        l_review_value[-1:-1] = l_review_value_stars\n",
    "\n",
    "        l_data_url += list(zip(l_review_value_header, l_review_value))\n",
    "        l_df.append(l_data_url)\n",
    "        \n",
    "        #Transform our data to dataframes\n",
    "    dfs = [pd.DataFrame(l) for l in l_df]\n",
    "\n",
    "    #Merge accoring to column 0\n",
    "    df = reduce(lambda left,right: pd.merge(left,right,on=0, how='outer'), dfs)\n",
    "\n",
    "    #Get the right format of dataframe\n",
    "    df_reviews = df.T.copy()\n",
    "    df_reviews.columns = df_reviews.iloc[0]\n",
    "    df_reviews.drop(df_reviews.index[0], inplace=True)\n",
    "    df_reviews.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapping, it's better to launch it on google colab I think"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scraped_companies = ['air-france',\n",
    " 'american-airlines',\n",
    " 'air-china',\n",
    " 'lufthansa',\n",
    " 'emirates',\n",
    " 'ana-all-nippon-airways',\n",
    " 'latam-airlines',\n",
    " 'aeroflot-russian-airlines',\n",
    " 'air-canada',\n",
    " 'singapore-airlines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dfs = []\n",
    "for companie in scraped_companies:\n",
    "    global_url = 'https://www.airlinequality.com/airline-reviews/{}/'.format(str(companie))\n",
    "    print(global_url)\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    req = Request(global_url,headers=hdr)\n",
    "    page = urlopen(req)\n",
    "    soup = BeautifulSoup(page)\n",
    "    pages = soup.find('article', {'class':'comp comp_reviews-pagination querylist-pagination position-'})\n",
    "    l_pages = pages.find_all('li')\n",
    "    max_page = int(l_pages[-2].text.strip())\n",
    "    print(max_page)\n",
    "    for n_page in range(max_page) :\n",
    "        company_url = global_url + 'page/{}'\n",
    "        url = company_url.format(str(n_page))\n",
    "        print(url)\n",
    "        df = scraping_airlinequality(url)\n",
    "        results_dfs.append(df)\n",
    "df_reviews = pd.concat(results_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020, 24)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
